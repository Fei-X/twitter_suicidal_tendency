{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/data_after_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tf-count and topic model for tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The lemmatization does not work really well.\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# df['tweet'] = df['tweet'].apply(lambda x:' '.join(WordNetLemmatizer().lemmatize(i) for i in x.split(' ')))\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Adding a list of stop words to the wordlist\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(['suicidal','bc','did','didn','t','does','doesn','don','dont','doing','going','gonna','having','isn','ll','ve','wanna','want','wanted','wanting','wasn','went','yes','yeah'])\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=0.01, stop_words=my_stop_words)\n",
    "x = count_vectorizer.fit_transform(df['tweet'])\n",
    "\n",
    "n,m = x.shape\n",
    "k = 20 # try for 20 topics\n",
    "lda = LatentDirichletAllocation(n_components=k, random_state=2021)\n",
    "xtr = lda.fit_transform(x)\n",
    "\n",
    "# So xtr will be new features to replace 'tweet'\n",
    "data_x = pd.DataFrame(xtr).add_prefix('topic_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take log for some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_log = ['nlikes', 'nreplies', 'nretweets','join_time', 'tweets', 'following', 'followers', 'likes', 'media']\n",
    "# for feature in features_to_log:\n",
    "#     data_x[feature] = np.log1p(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_log = ['nlikes', 'nreplies', 'nretweets','join_time']\n",
    "for feature in features_to_log:\n",
    "    data_x[feature] = np.log1p(df[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'day' take absolute values, tweet_length take min-max scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = (df['day'] - 4).abs()\n",
    "df['tweet_length'] = df['tweet_length'] / df['tweet_length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_add = ['day','url','tweet_length', 'tweet_sentiment', 'bio_sentiment', 'first_person', 'second_person', 'third_person','tweets_binning','following_binning','followers_binning','likes_binning','media_binning']\n",
    "for feature in features_to_add:\n",
    "    data_x[feature] = df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>bio_sentiment</th>\n",
       "      <th>first_person</th>\n",
       "      <th>second_person</th>\n",
       "      <th>third_person</th>\n",
       "      <th>tweets_binning</th>\n",
       "      <th>following_binning</th>\n",
       "      <th>followers_binning</th>\n",
       "      <th>likes_binning</th>\n",
       "      <th>media_binning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.131315</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.131744</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
       "0  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500   \n",
       "1  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500  0.262500   \n",
       "2  0.006250  0.131315  0.006250  0.131744  0.006250  0.006250  0.006250   \n",
       "3  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "4  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "\n",
       "    topic_7   topic_8   topic_9  ...  tweet_sentiment  bio_sentiment  \\\n",
       "0  0.012500  0.012500  0.012500  ...                2              2   \n",
       "1  0.012500  0.012500  0.012500  ...                2              2   \n",
       "2  0.506250  0.006250  0.006250  ...                2              2   \n",
       "3  0.016667  0.016667  0.016667  ...                0              2   \n",
       "4  0.025000  0.025000  0.025000  ...                2              2   \n",
       "\n",
       "   first_person  second_person  third_person  tweets_binning  \\\n",
       "0             0              0             0             3.0   \n",
       "1             1              0             0             4.0   \n",
       "2             0              0             1             2.0   \n",
       "3             1              0             0             3.0   \n",
       "4             0              0             0             4.0   \n",
       "\n",
       "   following_binning  followers_binning  likes_binning  media_binning  \n",
       "0                2.0                1.0            3.0            2.0  \n",
       "1                2.0                3.0            4.0            2.0  \n",
       "2                1.0                0.0            2.0            0.0  \n",
       "3                2.0                2.0            4.0            2.0  \n",
       "4                3.0                3.0            2.0            1.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data_x, data_y, test_size = 0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is cost-sensitive, i.e. it's more costly to wrongly classify 2 as 0 than classify 1 as 0.  \n",
    "So we can assign some class weight to each class, adding the penalty for wrongly classifying label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The evaluation report of OVR is:\n",
      "Confusion Matrix:\n",
      "[[1017  180  260]\n",
      " [ 154  110  159]\n",
      " [  83   61  264]]\n",
      "Accuracy: 0.6079545454545454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "estimator = linear_model.LogisticRegression(class_weight='balanced',\n",
    "                                            multi_class='ovr',\n",
    "                                            C=0.01,\n",
    "                                            max_iter=1000)\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "y_pred = estimator.predict(x_test)\n",
    "report = \"\"\"\n",
    "The evaluation report of OVR is:\n",
    "Confusion Matrix:\n",
    "{}\n",
    "Accuracy: {}\n",
    "\"\"\".format(metrics.confusion_matrix(y_test, y_pred),\n",
    "           metrics.accuracy_score(y_test, y_pred))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The evaluation report of OVR is:\n",
      "Confusion Matrix:\n",
      "[[1451    0    6]\n",
      " [ 404    0   19]\n",
      " [ 355    0   53]]\n",
      "Accuracy: 0.6573426573426573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "report_NB = \"\"\"\n",
    "The evaluation report of OVR is:\n",
    "Confusion Matrix:\n",
    "{}\n",
    "Accuracy: {}\n",
    "\"\"\".format(metrics.confusion_matrix(y_test, y_pred),\n",
    "           metrics.accuracy_score(y_test, y_pred))\n",
    "print(report_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
