{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "df = pd.read_csv('data/data_after_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to take note before using this modelling notebook\n",
    "\n",
    "1. There are 2 approaches to using the text corpus  \n",
    "    a. LDA: Hard to explain because clusters are not labelled but dimensionality has been reduced to 5 (based on grid)  \n",
    "    b. TFIDF: 173 (based on vectorizer) tfidf float numbers exist per tweet. Easier explanability but high dimensionality)  \n",
    "2. A new feature \"day_after\" has been added. Remember to include it in the modelling step if you wish to.  \n",
    "3. Remember to do scaling on numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jingxue/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "df['tweet'] = df['tweet'].apply(lambda x:' '.join(WordNetLemmatizer().lemmatize(i) for i in x.split(' ')))\n",
    "\n",
    "# Remove punctuation\n",
    "df['tweet'] = df['tweet'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -234533.78816095451\n",
      "Perplexity:  146.7923650662626\n"
     ]
    }
   ],
   "source": [
    "# Run tf vectorizer\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Adding a list of stop words to the wordlist\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(['suicidal'])\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=0.01, stop_words=my_stop_words)\n",
    "\n",
    "# Use vectors for LDA\n",
    "\n",
    "x = count_vectorizer.fit_transform(df['tweet'])\n",
    "lda_model = LatentDirichletAllocation(n_components=5, learning_decay=0.7, random_state=2021)\n",
    "xtr = lda_model.fit_transform(x)\n",
    "\n",
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(x))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(x))\n",
    "\n",
    "data_x = pd.DataFrame(xtr).add_prefix('topic_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>youre</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>young</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>yes</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>year</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>yeah</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>wrong</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>worse</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>world</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>work</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>wont</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "112  youre  175\n",
       "58   young  174\n",
       "77     yes  173\n",
       "15    year  172\n",
       "162   yeah  171\n",
       "66   wrong  170\n",
       "109  worse  169\n",
       "36   world  168\n",
       "59    work  167\n",
       "71    wont  166"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_vectorizer.vocabulary_.items()).sort_values(1,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "#binning\n",
    "list_for_binning1 = ['nlikes', 'nreplies', 'nretweets', 'tweets', 'following', 'followers', 'likes', 'media']\n",
    "new_column1 = ['nlikes_binning','nreplies_binning','nretweets_binning','tweets_binning','following_binning','followers_binning','likes_binning','media_binning']\n",
    "for i in range(8):\n",
    "    new_col = new_column1[i]\n",
    "    col_for_binning = list_for_binning1[i]\n",
    "    data_x[new_col] = df[col_for_binning].apply(lambda x:0 if x==0 else np.floor(np.log10(x)))\n",
    "    \n",
    "list_for_binning2 = ['reply_to','join_time','day_after','tweet_length']\n",
    "new_column2 = ['reply_to_binning','join_time_binning','day_after_binning','tweet_length_binning']\n",
    "for i in range(4):\n",
    "    new_col = new_column2[i]\n",
    "    col_for_binning = list_for_binning2[i]\n",
    "    data_x[new_col] = df[col_for_binning].apply(lambda x:0 if x==0 else np.floor_divide(x,10))\n",
    "\n",
    "list_for_binning3 = ['topic_0','topic_1','topic_2','topic_3','topic_4']\n",
    "# new_column2 = ['topic_0_binning','topic_1_binning','topic_2_binning','topic_3_binning','topic_4_binning']\n",
    "for i in range (5):\n",
    "#     new_col = new_column3[i]\n",
    "    col_for_binning = list_for_binning3[i]\n",
    "    data_x[col_for_binning] = data_x[col_for_binning].apply(lambda x:0 if x==0 else np.floor_divide(100*x,10))\n",
    "    \n",
    "# 'day' take absolute values.\n",
    "df['day'] = (df['day'] - 4).abs()\n",
    "\n",
    "# Adding features\n",
    "features_to_add = ['day','url','tweet_sentiment', 'bio_sentiment', 'first_person', 'second_person', 'third_person']\n",
    "for feature in features_to_add:\n",
    "    data_x[feature] = df[feature]\n",
    "    \n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# data_x.iloc[:, 5:] = scaler.fit_transform(data_x.iloc[:, 5:])\n",
    "data_y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25,25))\n",
    "# lst = ['day','reply_to', 'url', 'day_after','tweet_length', 'tweet_sentiment']\n",
    "# for i in range(7):\n",
    "#     plt.subplot(3,3,i+1)\n",
    "#     plt.hist(df[lst[i]],bins=10);\n",
    "#     plt.xlabel(lst[i])\n",
    "#     plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data_x, data_y, test_size = 0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold:  0.03\n",
      "\n",
      "The evaluation report of classification is:\n",
      "Confusion Matrix:\n",
      "[[675 771]\n",
      " [ 42 360]]\n",
      "Accuracy: 0.560064935064935\n",
      "Precision: 0.3183023872679045\n",
      "Recall: 0.8955223880597015\n",
      "F2 Score: 0.6571741511500548\n",
      "AUC Score: 0.7770672914817339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = naive_bayes.MultinomialNB(alpha = 1)\n",
    "estimator.fit(x_train, y_train)\n",
    "y_pred_proba = estimator.predict_proba(x_test)\n",
    "dic = evaluate.threshold(y_pred_proba,y_test)\n",
    "print('Selected threshold: ', dic['threshold'])\n",
    "print(evaluate.performance(y_test, dic['y_pred'],y_pred_proba)['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with real time available features\n",
    "data in this part will have no features in 'nlikes', 'nreplies', 'nretweets' and 'day_after' becasue these features are received a few days after the tweets were posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rt = x_train.drop(columns=['nlikes_binning', 'nreplies_binning', 'nretweets_binning', 'day_after_binning'])\n",
    "x_test_rt = x_test.drop(columns=['nlikes_binning', 'nreplies_binning', 'nretweets_binning', 'day_after_binning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold:  0.03\n",
      "\n",
      "The evaluation report of classification is:\n",
      "Confusion Matrix:\n",
      "[[675 771]\n",
      " [ 42 360]]\n",
      "Accuracy: 0.560064935064935\n",
      "Precision: 0.3183023872679045\n",
      "Recall: 0.8955223880597015\n",
      "F2 Score: 0.6571741511500548\n",
      "AUC Score: 0.7770672914817339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model implementation\n",
    "estimator = naive_bayes.MultinomialNB(alpha = 1)\n",
    "estimator.fit(x_train, y_train)\n",
    "y_pred_proba = estimator.predict_proba(x_test)\n",
    "dic = evaluate.threshold(y_pred_proba,y_test)\n",
    "print('Selected threshold: ', dic['threshold'])\n",
    "print(evaluate.performance(y_test, dic['y_pred'],y_pred_proba)['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling using only tweet\n",
    "Other than using a LSTM to implement the classifier solely on tweet, we also try a mechine learning approach on tweet.  \n",
    "Using the count_vectorizer, we perform a naive bayes to classify.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold:  0.14\n",
      "\n",
      "The evaluation report of classification is:\n",
      "Confusion Matrix:\n",
      "[[692 754]\n",
      " [ 36 366]]\n",
      "Accuracy: 0.5725108225108225\n",
      "Precision: 0.3267857142857143\n",
      "Recall: 0.9104477611940298\n",
      "F2 Score: 0.6708211143695014\n",
      "AUC Score: 0.7933732100218134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_2, x_test_2, y_train_2, y_test_2 = model_selection.train_test_split(df['tweet'], df['label'], test_size = 0.2, random_state = 2021)\n",
    "count = CountVectorizer(min_df=0.01, stop_words=my_stop_words)\n",
    "x_train_2 = count.fit_transform(x_train_2)\n",
    "x_test_2 = count.transform(x_test_2)\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "mnb = naive_bayes.MultinomialNB()\n",
    "mnb.fit(x_train_2, y_train_2)\n",
    "y_pred_proba = mnb.predict_proba(x_test_2)\n",
    "dic = evaluate.threshold(y_pred_proba,y_test)\n",
    "print('Selected threshold: ', dic['threshold'])\n",
    "print(evaluate.performance(y_test, dic['y_pred'],y_pred_proba)['report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
